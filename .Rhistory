thick<-5
building<-building %>% mutate(
BoardFeet = (SquareFeet/(2000/16000))*thick*stud,
Acres = BoardFeet/100000,
Trees=182*Acres)
building
t.building2 <- building[, c(1,6,7)] %>%
head(6)
t.building2 %>%
kable("html", caption = 'Some example recently-constructed mass timber buildings with their total square footage.') %>%
# kable_styling(position = "center") %>%
kable_styling()
t.building2 <- building[, c(1,6,7,8)] %>%
head(6)
t.building2 %>%
kable("html", caption = 'Some example recently-constructed mass timber buildings with their total square footage.') %>%
# kable_styling(position = "center") %>%
kable_styling()
stud<-8
thick<-5
building<-building %>% mutate(
BoardFeet = (SquareFeet/(2000/16000))*thick*stud,
Acres = round(BoardFeet/100000),
Trees=round(182*Acres))
building
t.building2 <- building[, c(1,6,7,8)] %>%
head(6)
t.building2 %>%
kable("html", caption = 'Some example recently-constructed mass timber buildings with their total square footage.') %>%
# kable_styling(position = "center") %>%
kable_styling()
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
options(scipen=999)
library(tidyverse)
library(GGally)
library(knitr)
library(formattable)
library(kableExtra)
# Chunk 2
building<-data.frame(Building=c("T3","Carbon12","T3 West Midtown","Brock Commons Tallwood House","The Cube Building"),
Location=c("Minneapolis, MN","Portland, OR","Atlanta, GA","Vancouver, BC","London, UK"),
YearBuilt=c(2016,2018,2018,2017,2015),
Stories=c(7,8,7,18,10),
SquareFeet=c(224000,42000,205000,162700,72650))
building
# Chunk 3
t.building <- building[, 1:4] %>%
head(6)
t.building %>%
kable("html", caption = 'Some example recently-constructed mass timber buildings with their total square footage.') %>%
kable_styling()
# Chunk 4
stud<-8
thick<-5
building<-building %>% mutate(
BoardFeet = (SquareFeet/(2000/16000))*thick*stud,
Acres = round(BoardFeet/100000),
Trees=round(182*Acres))
building
t.building2 <- building[, c(1,6,7,8)] %>%
head(6)
t.building2 %>%
kable("html", caption = 'Estimates of total board feet, acres harvested, and total number of trees needed to contruct mass timber buildings.') %>%
kable_styling()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(systemfit)
library(nlme)
library(lqmm)
# Chunk 2
#Dataset = 736,553 observations, downloaded 11 May 2019
dwd.raw<-read.csv('C://Users//russellm//Documents//Projects//DWDModels//Data//DWM_COARSE_WOODY_DEBRIS.csv')
plot.raw<-read.csv('C://Users//russellm//Documents//Projects//DWDModels//Data//PLOT.csv')
plot.raw<-plot.raw %>%
select(STATECD,COUNTYCD,PLOT,INVYR,ECOSUBCD,LAT,LON,ELEV)
dwd<-merge(dwd.raw,plot.raw,by=c("STATECD","COUNTYCD","PLOT","INVYR"))
dwd<-dwd %>%
select(STATECD,COUNTYCD,PLOT,INVYR,ECOSUBCD,LAT,LON,ELEV,SUBP,TRANSECT,CWDID,MEASYEAR,CONDID,SLOPDIST,HORIZ_DIST, SPCD,DECAYCD,TRANSDIA,SMALLDIA,LARGEDIA,LENGTH,HOLLOWCD,CWDHSTCD,ECOSUBCD,LAT,LON,ELEV)
dwd<-mutate(dwd, ECOSUB = substr(ECOSUBCD,2,4))
dwd$ECOSUB<-ifelse(dwd$ECOSUB %in% c("33A"),"333",dwd$ECOSUB)
dwd$ECOSUB<-ifelse(dwd$ECOSUB %in% c(""),"999",dwd$ECOSUB)
dwd.eco<-dwd %>%
group_by(ECOSUB)%>%
summarize(n=n())
dwd.eco
#Woodall et al. parameters
#Woodall CW, Westfall JA, Lutes DC, Oswalt SN (2008).
#End-point diameter and total length coarse woody debris models for the United States.
#For Ecol Manage 255:3700-3706
#Some ecogerions do not have parameters listed in Woodall et al.
#For these, parameters for a similar ecogerion were used:
#211 = 212
#223 = 221
#241 = 242
#411 = 255
#999 = average of parameters from all others
parm<-read.csv('C://Users//russellm//Documents//Projects//DWDModels//Data//dwdparms.csv')
#Read in species dataset to get major species group codes
spp<-read.csv('C://Users//russellm//Documents//Data//Species//REF_SPECIES.csv')
spp<-spp %>%
select(SPCD,MAJOR_SPGRPCD,SFTWD_HRDWD,COMMON_NAME)
#Remove Decay class 5 pieces
dwd2<-subset(dwd,DECAYCD<=4 & SPCD != 1)
dwd2$SPCD<-ifelse(dwd2$SPCD==0,999,dwd2$SPCD)
dwd3<-merge(dwd2,spp,by=c("SPCD"))
head(dwd3)
# Chunk 3
dwd.spp<-dwd3 %>%
group_by(COMMON_NAME)%>%
summarize(n=n())
dwd.spp$pct<-(dwd.spp$n/sum(dwd.spp$n)*100)
# Chunk 4
dwd3$SPGR<-ifelse(dwd3$SFTWD_HRDWD=="S","Sftwd","Hwd")
dwd3$SPGR<-ifelse(dwd3$ECOSUB %in% c(251,411,255,333,999),"All", dwd3$SPGR)
dwd4<-merge(dwd3,parm,by=c("ECOSUB","SPGR"))
# Chunk 5
dwd5<-dwd4 %>%
mutate(ELEV_m=ELEV*0.0348,
SLOPDIST_m=SLOPDIST*0.3048,
HORIZ_DIST_m=HORIZ_DIST*0.3048,
TRANSDIA_cm=TRANSDIA*2.54,
SMALLDIA_cm=SMALLDIA*2.54,
LARGEDIA_cm=LARGEDIA*2.54,
LENGTH_m=LENGTH*0.3048)
# Chunk 6
DIAM.hat<-function(b0,b1,b2,b3,DT,DC){
DIAM.hat=b0+(b1*DT)+(b2*DC)+(b3*(DT*DC))
return(DIAM.hat)
}
LTH.hat<-function(b0,b1,b2,b3,DS.hat,DL.hat,DC){
LTH.hat=b0+(b1*DS.hat)+(b2*DL.hat)+(b3*DC)
return(LTH.hat)
}
dwd5$DL.hat.woodall<-DIAM.hat(b0=dwd5$b0_ld,b1=dwd5$b1_ld,b2=dwd5$b2_ld,b3=dwd5$b3_ld,
DT=dwd5$TRANSDIA_cm,DC=dwd5$DECAYCD)
dwd5$DS.hat.woodall<-DIAM.hat(b0=dwd5$b0_sd,b1=dwd5$b1_sd,b2=dwd5$b2_sd,b3=dwd5$b3_sd,
DT=dwd5$TRANSDIA_cm,DC=dwd5$DECAYCD)
dwd5$LTH.hat.woodall<-LTH.hat(b0=dwd5$b0_lth,b1=dwd5$b1_lth,b2=dwd5$b2_lth,b3=dwd5$b3_lth,
DS.hat=dwd5$DS.hat.woodall,DL.hat=dwd5$DL.hat.woodall,DC=dwd5$DECAYCD)
# Chunk 7
p.DL<-ggplot(dwd5,aes(y=DL.hat.woodall,x=LARGEDIA_cm))+geom_point()+stat_smooth()+
xlab("Observed DL")+
ylab("Predicted DL from Woodall")+
theme(panel.background = element_rect(fill = "NA"))
#p.DL
p.DS<-ggplot(dwd5,aes(y=DS.hat.woodall,x=SMALLDIA_cm))+geom_point()+stat_smooth()+
xlab("Observed DS")+
ylab("Predicted DS from Woodall")+
theme(panel.background = element_rect(fill = "NA"))
#p.DS
p.LTH<-ggplot(dwd5,aes(y=LTH.hat.woodall,x=LENGTH_m))+geom_point()+stat_smooth()+
xlab("Observed length")+
ylab("Predicted length from Woodall")+
theme(panel.background = element_rect(fill = "NA"))
#p.LTH
#ggsave(filename = "C://Users//russellm//Documents//Projects//DWDModels//Analysis//p.DL.png", plot=p.DL,width=4,height=4,units="in",scale=1)
#ggsave(filename = "C://Users//russellm//Documents//Projects//DWDModels//Analysis//p.DS.png", plot=p.DS,width=4,height=4,units="in",scale=1)
#ggsave(filename = "C://Users//russellm//Documents//Projects//DWDModels//Analysis//p.LTH.png", plot=p.LTH,width=4,height=4,units="in",scale=1)
# Chunk 8
p.DSDT<-ggplot(dwd5,aes(y=SMALLDIA_cm,x=TRANSDIA_cm))+geom_point()+stat_smooth()+
xlab("Transect diameter (cm)")+
ylab("Small-end diameter (cm)")+
theme(panel.background = element_rect(fill = "NA"))
#p.DSDT
p.DLDT<-ggplot(dwd5,aes(y=LARGEDIA_cm,x=TRANSDIA_cm))+geom_point()+stat_smooth()+
xlab("Transect diameter (cm)")+
ylab("Large-end diameter (cm)")+
theme(panel.background = element_rect(fill = "NA"))
#p.DLDT
p.LTHDT<-ggplot(dwd5,aes(y=LENGTH_m,x=TRANSDIA_cm))+geom_point()+stat_smooth()+
xlab("Transect diameter (cm)")+
ylab("Length (m)")+
theme(panel.background = element_rect(fill = "NA"))
#p.LTHDT
# Chunk 9
DL_hat <- LARGEDIA_cm ~ TRANSDIA_cm + DECAYCD + (TRANSDIA_cm * DECAYCD)
DS_hat <- SMALLDIA_cm ~ TRANSDIA_cm + DECAYCD + (TRANSDIA_cm * DECAYCD)
LTH_hat <- LENGTH_m ~ TRANSDIA_cm + DECAYCD + (TRANSDIA_cm * DECAYCD)
system.linear <- list(LARGEDIA=DL_hat,SMALLDIA=DS_hat,LENGTH=LTH_hat)
inst<- ~ TRANSDIA_cm + DECAYCD + TRANSDIA_cm * DECAYCD
## OLS estimation
fit.ols.linear <- systemfit(system.linear, method="OLS", data=dwd5)
summary(fit.3sls.linear)
## 3SLS estimation
fit.3sls.linear <- systemfit(system.linear, method="3SLS", inst=inst, data=dwd5)
summary(fit.3sls.linear)
## SUR estimation
fit.sur.linear <- systemfit(system.linear, data=dwd5,method="SUR")
summary(fit.sur.linear)
#
# ##Nonlinear
# DL_hat <- LARGEDIA_cm ~ exp(a0+a1*TRANSDIA_cm + a2*DECAYCD + a3*(TRANSDIA_cm*DECAYCD))
# DS_hat <- SMALLDIA_cm ~ exp(b0+b1*TRANSDIA_cm + b2*DECAYCD + b3*(TRANSDIA_cm*DECAYCD))
# LTH_hat <- LENGTH_m ~ exp(c0+c1*TRANSDIA_cm + c2*DECAYCD + c3*(TRANSDIA_cm*DECAYCD))
#
# system.nonlinear <- list(DL_hat,DS_hat,LTH_hat)
# labels <- list( "Small-end diameter", "Large-end diameter", "Length" )
# start.values <- c(a0=5, a1=1.1, a2=-1, a3=-0.1,
#                   b0=3, b1=0.4, b2=-1, b3=0.2,
#                   c0=4, c1=0.1, c2=0.1, c3=-0.5)
#
# model.ols <- nlsystemfit( "OLS", system.nonlinear, start.values, data=dwd5, eqnlabels=labels )
# print( model.ols )
dwd.DL<-dwd5 %>% drop_na(LARGEDIA_cm,SMALLDIA_cm,DECAYCD,SPCD)
blogdown:::new_post_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
# Chunk 1
library(purrr)
library(ggplot2)
gap_split_small <- gap_split[1:10]
countries <- names(gap_split_small)
# For all countries
plots <- map2(gap_split_small, countries,
~ ggplot(.x, aes(year, lifeExp)) +
geom_line() +
labs(title = .y) +
coord_cartesian(ylim = c(0, 100)))
library(repurrrsive)
install.packages("repurrrsive")
library(purrr)
library(repurrrsive)
library(ggplot2)
gap_split_small <- gap_split[1:10]
countries <- names(gap_split_small)
# For all countries
plots <- map2(gap_split_small, countries,
~ ggplot(.x, aes(year, lifeExp)) +
geom_line() +
labs(title = .y) +
coord_cartesian(ylim = c(0, 100)))
# Display all plots
walk(plots, print)
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
eab<-gsheet2tbl('https://docs.google.com/spreadsheets/d/1S5ypnWcL0uOG50YrhxyAGHsQk356qyyDzTTCBkiXL80/edit?usp=sharing')
eab$state<-fips("MN")
eab$infest<-ifelse(eab$yearinfest>0,"YES","NO")
# Chunk 1: setup
#knitr::opts_chunk$set(echo = TRUE)
#library(devtools)
library(ggplot2) #Provides the visualization tools
library(gsheet) #Links to the data in a Google Sheet
library(GGally) #Extension of ggplot mapping attributes
library(rgdal) #Provides geospatial attributes
library(usmap) #Provides a basemap of the US
library(magick) #Processes images
eab<-gsheet2tbl('https://docs.google.com/spreadsheets/d/1S5ypnWcL0uOG50YrhxyAGHsQk356qyyDzTTCBkiXL80/edit?usp=sharing')
eab$state<-fips("MN")
eab$infest<-ifelse(eab$yearinfest>0,"YES","NO")
head(eab)
# Chunk 1: setup
#knitr::opts_chunk$set(echo = TRUE)
#library(devtools)
library(ggplot2) #Provides the visualization tools
library(gsheet) #Links to the data in a Google Sheet
library(GGally) #Extension of ggplot mapping attributes
library(rgdal) #Provides geospatial attributes
library(usmap) #Provides a basemap of the US
library(magick) #Processes images
# Chunk 2
eab<-gsheet2tbl('https://docs.google.com/spreadsheets/d/1S5ypnWcL0uOG50YrhxyAGHsQk356qyyDzTTCBkiXL80/edit?usp=sharing')
eab$state<-fips("MN")
eab$infest<-ifelse(eab$yearinfest>0,"YES","NO")
# Chunk 3
eab2009<-subset(eab,year==2009)
eab2010<-subset(eab,year==2010)
eab2011<-subset(eab,year==2011)
eab2012<-subset(eab,year==2012)
eab2013<-subset(eab,year==2013)
eab2014<-subset(eab,year==2014)
eab2015<-subset(eab,year==2015)
eab2016<-subset(eab,year==2016)
eab2017<-subset(eab,year==2017)
eab2018<-subset(eab,year==2018)
eab2019<-subset(eab,year==2019)
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
library(gsheet)
library(tidyverse)
# The dataset 'moose' is read in using the gsheet package and the gsheet2tbl() function.
moose<- gsheet2tbl('https://docs.google.com/spreadsheets/d/1l5489uILVkOiTuTD1uUM4DUkKXg9H04Q9yq9eZE5Tgs/edit?usp=sharing')
# The following code produces the mean, standard deviation,
# minimum, and maximum values of the moose estimates.
moose.mean<-moose %>%
summarize(mean.moose=mean(Mean),
sd.moose=sd(Mean),
min.moose=min(Mean),
max.moose=max(Mean))
moose.mean
# The following code makes a histogram of the moose estimates.
p.hist<-ggplot(moose, aes(x=Mean)) +
geom_histogram(binwidth=1000,position="dodge",color="black")+
xlab("Moose estimate")+
ylab("Number of students")+
theme(axis.line = element_line(color="black"),
axis.ticks = element_line(size = 0.5,color="black"),
legend.position= c(.75, .75),
legend.title=element_blank(),
axis.text = element_text(size=10,color="black"),
panel.background = element_rect(fill = "NA"))
p.hist
# The following code makes a boxplot of the moose estimates.
p.box<-ggplot(moose, aes(1,Mean)) +
geom_boxplot()+
ylab("Moose estimate")+
xlab(" ")+
#scale_y_continuous(limits = c(0,20000))+
theme(axis.line = element_line(color="black"),
axis.ticks.y = element_line(size = 0.5,color="black"),
# axis.text.x = element_blank(),
legend.position = "none",
axis.text.x = element_blank(),
axis.ticks.x = element_blank(),
panel.background = element_rect(fill = "NA"))
p.box
# The following code graphs the moose estimates.
# Also graphed with the Minnesota Department of Natural Resources estimate (3,030 moose).
p.mean<-ggplot(moose, aes(y=StudentID, x=Mean))+
geom_point()+
geom_vline(xintercept=3030,col="red")+
annotate("text", y = -1, x = 5000, label = "DNR estimate (2018): 3,030 moose",col="red")+
xlab("Number of moose")+
ylab("Student number")+
theme(axis.line = element_line(color="black"),
axis.ticks = element_line(size = 0.5,color="black"),
panel.background = element_rect(fill = "NA"))
p.mean
# How many people guessed higher than the actual value?
moose$guess<-ifelse(moose$Mean>=3030,"HIGHER","LOWER")
print(paste(round(sum(moose$guess=="HIGHER")/length(moose$guess),2)*100,"% of students guessed HIGHER than the actual number of moose (3,030)"))
# The following code graphs the 50% confidence intervals and means.
p.50<-ggplot(moose, aes(y=StudentID, x=Mean))+
geom_point(size=1)+
geom_vline(xintercept=3030,col="red")+
geom_errorbarh(aes(xmin=Lower50, xmax=Upper50, height=0.01))+
annotate("text", label = "50% confidence", y = 18, x = 20000)+
xlab("Number of moose")+
ylab("Student ID")+
scale_x_continuous(limits = c(0,30000))+
theme(axis.line = element_line(color="black"),
axis.ticks = element_line(size = 0.5,color="black"),
panel.background = element_rect(fill = "NA"),
axis.text = element_text(size=10,color="black"),
legend.position = "none")
p.50
moose$guess50<-ifelse(moose$Lower50<=3030 &
moose$Upper50 >=3030,"INSIDE","OUTSIDE")
print(paste(round(sum(moose$guess50=="INSIDE")/
length(moose$guess50),2)*100,
"% of students guessed a 50% confidence interval that contains the actual number of moose (3,030)"))
# The following code graphs the 90% confidence intervals and means.
p.90<-ggplot(moose, aes(y=StudentID, x=Mean))+
geom_point(size=1)+
geom_rect(aes(xmin=2320, xmax=4140, ymin=0, ymax=Inf,col="red",fill="red"))+
geom_errorbarh(aes(xmin=Lower90, xmax=Upper90, height=0.01))+
annotate("text", label = "90% confidence", y = 17, x = 20000)+
xlab("Number of moose")+
ylab("Student ID")+
scale_x_continuous(limits = c(0,30000))+
theme(axis.line = element_line(color="black"),
axis.ticks = element_line(size = 0.5,color="black"),
panel.background = element_rect(fill = "NA"),
axis.text = element_text(size=10,color="black"),
legend.position = "none")
p.90
# How many people guessed a 90% interval that contained the actual value?
# The following code prints this value.
moose$guess90<-ifelse(moose$Lower90<=3030 &
moose$Upper90 >=3030,"INSIDE","OUTSIDE")
print(paste(round(sum(moose$guess90=="INSIDE")/
length(moose$guess90),2)*100,
"% of students guessed a 90% confidence interval that contains the actual number of moose (3,030)"))
View(moose)
blogdown:::insert_image_addin()
# First, we'll load some R packages using library().
# NOTE: If you have not used these R packages before, install them first:
# install.packages("gsheets")
# install.packages("tidyverse")
library(gsheet)
library(tidyverse)
# The dataset 'moose' is read in using the gsheet package and the gsheet2tbl() function.
moose<- gsheet2tbl('https://docs.google.com/spreadsheets/d/15xz_BcbKPJyX1F2VvjiwcBfOuK7KfGbjNJMjfPPM02U/edit?usp=sharing')
| Question | Mean response (number of moose) | “True” estimate (number of moose) |
|---------------------------:|------------------:|------------------------:|
| How many moose are currently found in Minnesota? | 4,460 | 3.030 |
| What is the LOWER value for your 50% confidence interval? | 2,866 | - |
| What is the UPPER value for your 50% confidence interval? | 6,011 | - |
| What is the LOWER value for your 90% confidence interval? | 1,878 | 2,320 |
| What is the UPPER value for your 90% confidence interval? | 7,784 | 4,140 |
| Question | Mean response (number of moose) | “True” estimate (number of moose) |
|----------------------------------------------------------------------------|------------------|------------------------|
| How many moose are currently found in Minnesota? | 4,460 | 3.030 |
| What is the LOWER value for your 50% confidence interval? | 2,866 | - |
| What is the UPPER value for your 50% confidence interval? | 6,011 | - |
| What is the LOWER value for your 90% confidence interval? | 1,878 | 2,320 |
| What is the UPPER value for your 90% confidence interval? | 7,784 | 4,140 |
# First, we'll load some R packages using library().
# NOTE: If you have not used these R packages before, install them first:
# install.packages("gsheets")
# install.packages("tidyverse")
library(gsheet)
library(tidyverse)
library(gridExtra)
# The dataset 'moose' is read in using the gsheet package and the gsheet2tbl() function.
moose<- gsheet2tbl('https://docs.google.com/spreadsheets/d/15xz_BcbKPJyX1F2VvjiwcBfOuK7KfGbjNJMjfPPM02U/edit?usp=sharing')
moose.mean<-moose_all%>%
summarize(mean.moose=mean(Mean))
moose.mean
moose.sum<-moose_all %>%
group_by(Class) %>%
summarize(n.moose=n())
moose.sum
moose<-subset(moose_all,Mean<50000)
moose<-subset(moose_all,Mean<50000&Upper90<50000&Mean>Lower50&Mean>Lower90&Mean<Upper50&Mean<Upper90)
moose.sum<-moose %>%
summarize(n.moose=n(),
mean.moose=mean(Mean),
mean.Lower50=mean(Lower50),
mean.Upper50=mean(Upper50),
mean.Lower90=mean(Lower90),
mean.Upper90=mean(Upper90))
moose.sum
moose.class<-moose %>%
group_by(Class) %>%
summarize(n.moose=n(),
mean.moose=mean(Mean),
mean.Lower50=mean(Lower50),
mean.Lower90=mean(Lower90),
mean.Upper50=mean(Upper50),
mean.Upper90=mean(Upper90))
moose.class
# First, we'll load some R packages using library().
# NOTE: If you have not used these R packages before, install them first:
# install.packages("gsheets")
# install.packages("tidyverse")
library(gsheet)
library(tidyverse)
library(gridExtra)
# The dataset 'moose' is read in using the gsheet package and the gsheet2tbl() function.
moose_all<- gsheet2tbl('https://docs.google.com/spreadsheets/d/15xz_BcbKPJyX1F2VvjiwcBfOuK7KfGbjNJMjfPPM02U/edit?usp=sharing')
moose.mean<-moose_all%>%
summarize(mean.moose=mean(Mean))
moose.mean
moose.sum<-moose_all %>%
group_by(Class) %>%
summarize(n.moose=n())
moose.sum
moose<-subset(moose_all,Mean<50000)
moose<-subset(moose_all,Mean<50000&Upper90<50000&Mean>Lower50&Mean>Lower90&Mean<Upper50&Mean<Upper90)
moose.sum<-moose %>%
summarize(n.moose=n(),
mean.moose=mean(Mean),
mean.Lower50=mean(Lower50),
mean.Upper50=mean(Upper50),
mean.Lower90=mean(Lower90),
mean.Upper90=mean(Upper90))
moose.sum
moose.class<-moose %>%
group_by(Class) %>%
summarize(n.moose=n(),
mean.moose=mean(Mean),
mean.Lower50=mean(Lower50),
mean.Lower90=mean(Lower90),
mean.Upper50=mean(Upper50),
mean.Upper90=mean(Upper90))
moose.class
p.hist<-ggplot(moose, aes(x=Mean, fill=Class2)) +
geom_histogram(binwidth=2000,position="dodge",color="black")+
xlab("Moose estimate")+
ylab("Number of students")+
scale_x_continuous(limits = c(0,20000))+
theme(axis.line = element_line(color="black"),
axis.ticks = element_line(size = 0.5,color="black"),
# axis.text.x = element_blank(),
legend.position= c(.75, .75),
legend.title=element_blank(),
axis.text = element_text(size=10,color="black"),
panel.background = element_rect(fill = "NA"))
p.hist
p.box<-ggplot(moose, aes(Class2,Mean)) +
geom_boxplot(aes(fill=Class2))+
ylab("Moose estimate")+
xlab(" ")+
scale_y_continuous(limits = c(0,20000))+
theme(axis.line = element_line(color="black"),
axis.ticks = element_line(size = 0.5,color="black"),
# axis.text.x = element_blank(),
legend.position = "none",
axis.text = element_text(size=10,color="black"),
panel.background = element_rect(fill = "NA"))
p.box
blogdown:::serve_site()
blogdown:::serve_site()
